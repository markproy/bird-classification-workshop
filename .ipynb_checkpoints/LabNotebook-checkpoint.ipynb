{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 Notebook - Preparing images for training\n",
    "\n",
    "This Jupyter notebook steps you through preparing the bird images dataset for training.  The images have been downloaded for you ahead of time.  In this lab, you will examine them to get an understanding of the raw input required for supervised learning of SageMaker's [Image Classification algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html).  You will then package the images into a specific format required by that algorithm.  Lastly, you will upload those packaged files to your S3 bucket for use in training the model.\n",
    "\n",
    "## Jupyter notebook basics\n",
    "\n",
    "If you are already familiar with how to execute Jupyter notebooks, please proceed to the next cell.  \n",
    "\n",
    "For those of you that are fairly new to using Jupyter notebooks, here are a couple of items to get you started:\n",
    "\n",
    "* This notebook has two types of cells: Code and Markdown.  This cell is a Markdown (documentation) cell.  As you proceed through the notebook, you'll read the documentation in these cells to understand the steps being taken.\n",
    "* Code cells are formatted differently and have tracking information to the left of the cell: `In [ ]`.  If there is a blank between the brackets, the cell has not yet been executed.  If there is a number between the brackets, that number indicates the sequence in which the cell was executed (1 for the first, 2 for the next, and so on).  If there is an asterisk in the brackets (i.e., `In [*]`, the cell is currently executing, or is waiting for some cell before it to complete before it will begin executing.\n",
    "* To execute a code cell, simply click on the `Cell` menu and click `Run Cells and Select Below`.  Or, much more conveniently, simply press Shift-Enter (i.e., the Shift key and the Enter key at the same time).\n",
    "* You can use the arrow keys on your keyboard (not the up and down arrow icons below the menu bar) to move back and forth between cells.\n",
    "\n",
    "Online help is provided from the `Help` menu.  You can also find tutorials for Jupyter with a simple web search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Define parameters for the notebook\n",
    "\n",
    "The only parameter you need to provide for Lab 1 is the S3 bucket name.  Set it to the name of your S3 bucket.  Note that the S3 bucket name is not the URI to the bucket.  It is not `s3://deeplens-sagemaker-20181126-smithjohn-2`, but instead it is just `deepelens-sagemaker-20181126-smithjohn-2`.\n",
    "\n",
    "TRAIN_RATIO is used to identify the percentage of the images to use as training images.  The remaining images are used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = '<bucket-name>'  # name of bucket you created, something like deeplens-sagemaker-20181126-smithjohn\n",
    "\n",
    "TRAIN_RATIO = 0.75\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Add required Python packages\n",
    "\n",
    "This workshop requires MXNet, which also requires OpenCV.  Install the corresponding Python packages in this next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mxnet \n",
    "! pip install opencv-python \n",
    "\n",
    "# for some reason, boto3 can get errors with certain versions of the AWS CLI.\n",
    "# To avoid hitting errors like 'serviceID not defined in the medata ...', we install\n",
    "# a specific AWS CLI verion.\n",
    "! pip install awscli==1.16.9 awsebcli==3.14.4 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Explore the images dataset\n",
    "\n",
    "For a 2 hour workshop, we do not have time to work with the complete NABirds dataset of 48,000+ images.  Instead, we operate on a very small subset but go through the entire process that would be used for the complete set.  For the workshop, we use 4 species, and you'll see 4 corresponding subdirectories in the `images` directory.  For the full dataset, you would see 555 species / subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd ~/SageMaker/bird-classification-workshop\n",
    "! ls images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine images for each sample species\n",
    "\n",
    "For each species, there are dozens of images of various shapes and sizes.  By dividing the entire dataset into individual named (numbered) folders, the images are in effect labelled for supervised learning using an image classification algorithm.  The following function shows a grid of thumbnail images for all the image files for a given species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_species(species_id):\n",
    "    _im_list = !ls ~/SageMaker/bird-classification-workshop/images/$species_id\n",
    "\n",
    "    print('Initializing a large matplotlib.pylot figure...')\n",
    "\n",
    "    NUM_COLS = 4\n",
    "    IM_COUNT = len(_im_list)\n",
    "\n",
    "    print('Species ' + species_id + ' has ' + str(IM_COUNT) + ' images.')\n",
    "    \n",
    "    NUM_ROWS = int(IM_COUNT / NUM_COLS)\n",
    "    if ((IM_COUNT % NUM_COLS) > 0):\n",
    "        NUM_ROWS += 1\n",
    "\n",
    "    fig, axarr = plt.subplots(NUM_ROWS, NUM_COLS)\n",
    "    fig.set_size_inches(8.0, 32.0, forward=True)\n",
    "\n",
    "    print('Reading each image file and showing it in a grid (this could take a few seconds)...')\n",
    "    curr_row = 0\n",
    "    for curr_img in range(IM_COUNT):\n",
    "        # fetch the url as a file type object, then read the image\n",
    "        f = 'images/' + species_id + '/' + _im_list[curr_img]\n",
    "        a = plt.imread(f)\n",
    "\n",
    "        # find the column by taking the current index modulo 3\n",
    "        col = curr_img % NUM_ROWS\n",
    "        # plot on relevant subplot\n",
    "        axarr[col, curr_row].imshow(a)\n",
    "        if col == (NUM_ROWS - 1):\n",
    "            # we have finished the current row, so increment row counter\n",
    "            curr_row += 1\n",
    "\n",
    "    fig.tight_layout()       \n",
    "\n",
    "    print('Displaying thumbnails of all images in this folder (this could take a few seconds)...')\n",
    "    plt.show()\n",
    "        \n",
    "    # Clean up\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purple Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_species('0752')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Northern Cardinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_species('0772')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### American Goldfinch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_species('0794')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eastern Bluebird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_species('0842')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at thumbnails of the images\n",
    "\n",
    "Now that you have captured thumbnail images for each species for this workshop, examine them and notice the variety:\n",
    "\n",
    "* image aspect ratios\n",
    "* image sizes\n",
    "* size of the bird relative to the scene\n",
    "* background of the scene\n",
    "\n",
    "It is important to have a wide variety to ensure that the trained model is capable of making robust predictions when fed arbitrary new images.  Note that when we train the image classification model, SageMaker gives us an `augmentation` hyperparameter.  When set to `crop`, it will double the number of training images on your behalf, make a copy of each and flipping the image on the horizontal axis.  So, if the original image has a bird facing to the left, a copy will be added with the bird facing to the right.  This boosts the ability of the model to handle new images, as they could be facing in any direction.\n",
    "\n",
    "Let's proceed to package the images in the format required by SageMaker's Image Classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Package the images in RecordIO format\n",
    "\n",
    "The following figure illustrates the process of packaging the images.\n",
    "\n",
    "![](./docs/screenshots/prepare_images.png)\n",
    "\n",
    "To use these images with SageMaker's Image Classification algorithm, they need to be packaged in RecordIO format.  RecordIO format enables you to put the entire set of training images into a single file, and all of the validation images into a second file.  For large datasets with tens of thousands or hundreds of thousands of images, [Apache MXNet RecordIO](https://mxnet.incubator.apache.org/architecture/note_data_loading.html) format makes transferring images and iterating on sets of images significantly more efficient.  \n",
    "\n",
    "Packaging the images involves 2 steps:\n",
    "\n",
    "1. Generate the list file containing the filenames of the images and the species identifier.  There is one `.lst` file created for training images and another for validation images.\n",
    "2. Use the list files to create binary `.rec` files, one for training and another for validation.\n",
    "\n",
    "MXNet provides a Python script called `im2rec` (**image** file to **RecordIO** file) to make it easy to perform these steps.\n",
    "\n",
    "### Generate .lst files\n",
    "\n",
    "The next cell does the first step of creating the `.lst` files given a ratio for the split between training data and validation data.  Notice the significant size difference between the two files.  We also display the tail of the validation file, so you can see the format which has 3 columns:\n",
    "\n",
    "1. A unique number for the file within the total set of images.\n",
    "2. The label for this image.  The label is a number between 0 and one less than the number of total classes / categories / species.  In our workshop, we are using only 4 species, so the label is one of 0, 1, 2, or 3.\n",
    "3. The relative path to the image file from the `images` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd ~/SageMaker/bird-classification-workshop/labs/lab1\n",
    "\n",
    "print('\\nGenerating .lst files.  This could take a minute...\\n')\n",
    "! python im2rec.py --list --recursive --train-ratio $TRAIN_RATIO nabirds_sample ../../images/\n",
    "\n",
    "print('\\nHere are the resulting files:')\n",
    "! ls -l *.lst\n",
    "\n",
    "print('\\nHere are the last few lines of the validation list file:')\n",
    "! tail *val.lst\n",
    "\n",
    "print('\\nShow the number of training images by counting lines in the list file.')\n",
    "! more nabirds_sample_train.lst | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the Image Classification model, you will need to know the number of training images. You can use the linux wc command to count the number of lines in the training list file, as shown in the previous code cell.  Note that the  TRAIN_RATIO defined at the start of this notebook controls the percentage of images used for training.  A higher ratio will yield more training images, but can lead to overfitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate .rec files\n",
    "\n",
    "Now that the `.lst` files are created, the next step is to create the RecordIO files.  For the workshop, since we are only working with 4 species, the `.rec` files are not that large.  The full dataset of NABirds images contains 555 species, making the resulting `.rec` files more than 100 times larger than these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating packaged RecordIO files.  This could take a minute...\\n')\n",
    "! python im2rec.py --resize 256 nabirds_sample ../../images/\n",
    "\n",
    "print('\\nHere are the resulting files:')\n",
    "! ls -l *.rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Make the .rec files available for training\n",
    "\n",
    "Now that the `.rec` files have been created, they must be made available in S3.  The SageMaker training job pulls the `.rec` files from S3 at the start of the job, and it creates the model artifacts in S3 once training is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Copying the packaged RecordIO files to S3 (this could take a minute)...')\n",
    "! aws s3 cp nabirds_sample_train.rec s3://$BUCKET_NAME/train/nabirds_sample_train.rec\n",
    "! aws s3 cp nabirds_sample_val.rec s3://$BUCKET_NAME/validation/nabirds_sample_val.rec\n",
    "\n",
    "print('\\nHere are the resulting files in S3:')    \n",
    "! aws s3 ls s3://$BUCKET_NAME/train/\n",
    "! aws s3 ls s3://$BUCKET_NAME/validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the S3 console and locate your newly uploaded `.rec` files.\n",
    "\n",
    "You have completed preparation of the bird images dataset as input to training a model based on SageMaker's Image Classification algorithm.  You can save the notebook and leave this browser tab.\n",
    "\n",
    "Proceed to Lab 2 of the workshop to perform the actual model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
